*Exploring AI, ML, and Generative Technologies in Heliophysics*

*A bi-weekly brief on AI, ML, and LLMs for the Heliophysics Science Division*

---
## ğŸ“Œ Introduction

Artificial Intelligence (AI) is the broad field of building smart machines. Machine Learning (ML) is a subset focused on training models to learn patterns from data. Large Language Models (LLMs) like GPT-4o or Claude Opus are a recent type of generative AI, capable of producing human-like text, code, and analysis. How do these technologies intersect with heliophysics research? Letâ€™s explore.

---

## ğŸ“… Upcoming Events

### ğŸ§  **NASA AI Center of Excellence â€“ Monthly Webinar**
ğŸ“† **Wednesday, October 8, 2025**  
ğŸ•š **11:00 AM â€“ 12:00 PM ET**  
ğŸ“ **Microsoft Teams**  
ğŸ” *Occurs the second Wednesday of every month*  

ğŸ‘‰ [**Join the Meeting**](https://teams.microsoft.com/l/meetup-join/19:meeting_YWFiMjE1YmQtNTQ5Yi00YTljLTg2YWItZjhlYjQ2ZmQ0YzNm%40thread.v2/0?context=%7b%22Tid%22:%227005d458-45be-48ae-8140-d43da96dd17b%22%2c%22Oid%22:%22414e48ef-3498-460e-8e58-960bd26d1d59%22%7d)  
ğŸ“ Dial-in: `+1 256-715-9946,,850427523#` (US â€“ Huntsville)  
ğŸ”¢ Phone Conference ID: `850 427 523#`  
ğŸ†” Meeting ID: `217 293 044 622`  
ğŸ”‘ Passcode: `F4bi3tK9`  

---

### ğŸ“ **NVIDIA GTC Conference**
ğŸ—“ï¸ **October 27â€“29, 2025** | ğŸ“ **Washington, DC**  
One of the most important AI events of the year.  

- **Training Day:** October 27 (paid courses)  
- **Main Conference:** October 28â€“29  
- **Free registration** for those with a `.gov` email  
- **NCTS#:** `52889-26`  
ğŸ”— [Register here](https://www.nvidia.com/gtc/dc/)

---

## ğŸ“š Key Terms of the Week

|Term|Definition|
|---|---|
|**Prompt Chaining**|Connecting multiple prompts together to complete complex, multi-step tasks.|
|**Grounding**|Providing models with trusted, domain-specific data to improve accuracy.|
|**Latent Space**|A compressed mathematical space where models organize concepts based on meaning or similarity.|
|**Token Limit**|The maximum number of tokens (input + output) a model can handle in a single exchange.|
|**Instruction Following**|A model's ability to respond precisely to natural language commands or requests.|
|**Zero-shot Learning**|Performing a task without seeing any task-specific examples during training.|
|**Fine-tuned Model**|A base model trained further on a smaller, specialized dataset for improved performance.|

## ğŸ’¬ NASA AI Policy Directive

NASA has just released a new interim policy directive on the use of AI. 

The document can be found at [NPD 1383.155](https://nodis3.gsfc.nasa.gov/OPD_Docs/NID_1383_155_.pdf "https://nodis3.gsfc.nasa.gov/OPD_Docs/NID_1383_155_.pdf")

So that you don't have to read the full document to have an idea of the content here is a summary thanks to ChatGSFC (Claude 4 Sonnet model).

### Core Policy Principles

- Authentic media is prioritized: NASA policy emphasizes using authentic (non-AI generated) imagery, audio, and video in all external materials and STI products when possible
- AI tools should complement, not replace: AI should support human expertise and institutional knowledge, not substitute for it

### When You Can Use AI Tools

- AI-generated, AI-assisted, and human-created media can only be used when authentic media isÂ not available or feasible
- You must use approved/authorized AI tools (maintained by the Chief AI Officer)
- Any use must maintain scientific and technical integrity

### Your Responsibilities as a NASA Employee

You must:

1. Understand and follow this policy
2. Properly labelÂ all AI-generated and AI-assisted media content
3. Embed appropriate metadataÂ in AI-generated content
4. Apply watermarksÂ to AI-generated media when required
5. Follow the latest guidance from the Chief AI Officer on using Generative AI

### What This Applies To

- All STI products you create or contribute to
- Visual and auditory content (images, audio, video) and their captions/descriptions
- Even media embedded in text-based materials
- Any media from external sources you incorporate into your work

### Compliance

- Regular reviews will verify compliance with this policy
- The policy covers both internal creation and any third-party media you use


---

### ğŸ’¡ Tips & Tricks (New Set)

- ğŸ§  **Start simple, then iterate:** Begin with a basic prompt and refine with follow-up questions or clarifications.
- ğŸ§¾ **Ask for structured formats:** Say "respond in bullet points," "give a table," or "summarize in 3 sentences" to control layout.
- ğŸ‘©â€ğŸ”¬ **Use domain-specific role prompts:** Ask the model to act like a heliophysicist, software engineer, or science communicator.
- ğŸªœ **Ask for reasoning steps:** Prompts like â€œshow your workâ€ or â€œwalk me through it step by stepâ€ improve transparency.
- ğŸ” **Re-use your best prompts:** Save and reuse high-performing promptsâ€”treat them like templates.
- ğŸ§­ **Use constraints to focus output:** Limit the response by time, topic, length, or audience to sharpen accuracy.
- ğŸ§° **Combine tools:** Use LLMs for text generation, and pair with code notebooks or data tools for computation.
    
---

### âš ï¸ Points of Caution (New Set)

- ğŸ” **Accurate â‰  Verified:** A model can _sound_ convincing while being completely wrong. Always verify outputs with trusted sources.
- ğŸ§ª **Scientific uncertainty is often omitted:** LLMs tend to present results as facts, even when confidence is low. Prompt for uncertainty explicitly.
- ğŸ’¾ **Session memory is short-term:** Most models forget previous conversations unless you restate context or use memory-enabled platforms.
- ğŸ“¤ **Cutoffs & outdated knowledge:** Models have training cutoffs and may miss recent papers, data releases, or policy updates.
- ğŸ—‚ï¸ **Formatting bugs:** Tables, code blocks, or LaTeX can break unexpectedlyâ€”check before copying into reports.
- ğŸ­ **Role confusion:** If you ask a model to act as an expert, it _will_â€”even if it doesnâ€™t know the subject.
- ğŸ›‘ **Model bias can mirror training data:** Responses can reflect outdated or skewed views unless carefully prompted or constrained.

---

## ğŸ§ª arXiv AI paper selections
### 1. **Federation of Agents: A Semantics-Aware Communication Fabric for Large-Scale Agentic AI**
**Authors:** Lorenzo Giusti, Ole Anton Werner, Riccardo Taiello, _et al._  
ğŸ”— [arXiv:2509.20175](https://doi.org/10.48550/arXiv.2509.20175)  
_Introduces a distributed orchestration system for multi-agent AI, enabling collaborative task decomposition, clustering, and semantic routing for complex, large-scale AI operations._

---

### 2. **Embodied AI: From LLMs to World Models**
**Authors:** Tongtong Feng, Xin Wang, Yu-Gang Jiang, _et al._  
ğŸ”— [arXiv:2509.20021](https://doi.org/10.48550/arXiv.2509.20021)  
_A comprehensive review of embodied AI architectures, combining Large Language Models (LLMs) and World Models (WMs) for bridging semantic reasoning with real-world physical interaction._

---

### 3. **Agentic Metacognition: Designing a "Self-Aware" Low-Code Agent for Failure Prediction and Human Handoff**
**Author:** Jiexi Xu  
ğŸ”— [arXiv:2509.19783](https://doi.org/10.48550/arXiv.2509.19783)  
_Proposes a metacognitive layer for autonomous agents in low-code environments, enabling intelligent failure prediction and transparent human handoff for better trust and usability._
---
## ğŸ§° Resources

### Internal
- [GSFC AI Center of Excellence](https://nasa.sharepoint.com/sites/GSFC-AI)
- [ChatGSFC Portal](https://nasa.sharepoint.com/sites/GSFC-AI/SitePages/ChatGSFC.aspx)
- [GSFC Code Assistant](https://nasa.sharepoint.com/sites/GSFC-AI/SitePages/GSFC-Code-Assistant.aspx)

### External
- [OpenAI Playground](https://platform.openai.com/playground)  
- [Anthropic Claude](https://claude.ai)  
- [Google Gemini](https://ai.google.dev)  
- [HuggingFace Spaces](https://huggingface.co/spaces)

---

> _â€œThink like a physicist. Prototype like a hacker. Document like a scientist.â€_

âœ‰ï¸ Questions or contributions?  
c.alex.young@nasa.gov | barbara.j.thompson@nasa.gov | christopher.bard@nasa.gov
